# Event Scraper - Trade Show Data Discovery Tool

A comprehensive GUI application for scraping trade show events with contact information and company data. Built with Python, Tkinter, and Selenium, this tool automates the collection of event data from trade show calendars.

## ğŸš€ Features

### Core Functionality
- **Web Scraping**: Automated extraction of trade show events from online calendars
- **Contact Information**: Gathers website URLs, email addresses, and company names
- **Smart Filtering**: Focuses on US-based events with intelligent date filtering
- **Excel Export**: Saves results to structured Excel files for easy analysis

### GUI Interface
- **Modern Tkinter GUI**: Clean, intuitive interface with tabbed navigation
- **Real-time Progress**: Live progress tracking with detailed logging
- **Configurable Settings**: Customizable scraping parameters and API keys
- **Individual Month Control**: Set specific years for each month (2025/2026)
- **Stop/Start Control**: Ability to pause and resume scraping operations

### Advanced Features
- **OpenAI Integration**: Uses GPT-4 for intelligent company name extraction
- **Multi-threaded**: Non-blocking GUI with background scraping
- **Error Handling**: Robust error recovery and user-friendly messages
- **Configuration Persistence**: Saves settings between sessions

## ğŸ“‹ Requirements

### System Requirements
- **Windows 10/11** (Primary target)
- **Python 3.8+** (3.12 recommended)
- **Chrome Browser** (for Selenium WebDriver)
- **4GB+ RAM** (for large scraping operations)
- **Internet Connection** (for web scraping and API calls)

### Python Dependencies
```
selenium>=4.0.0
beautifulsoup4>=4.9.0
openpyxl>=3.0.0
requests>=2.25.0
openai>=1.0.0
python-dotenv>=0.19.0
pyinstaller>=5.0.0
```

## ğŸ› ï¸ Installation

### Option 1: Pre-built Executable (Recommended)
1. Download `EventScraper.exe` from the releases
2. Run the executable directly

### Option 2: From Source
1. **Clone the repository**:
   ```bash
   git clone <repository-url>
   cd prospect-data-discovery-project
   ```

2. **Create virtual environment**:
   ```bash
   python -m venv venv
   .\venv\Scripts\activate  # Windows
   ```

3. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

4. **Set up environment variables**:
   - Create `.env` file with your OpenAI API key
   - Or set system environment variable `OPENAI_API_KEY`

5. **Run the application**:
   ```bash
   python event_scraper_gui.py
   ```

## ğŸ¯ Usage

### Quick Start
1. **Launch the application** (GUI will appear)
2. **Configure settings** in the Settings tab:
   - Enter your OpenAI API key
   - Adjust scraping parameters if needed
   - Select months and set years (2025/2026)
3. **Start scraping** by clicking "Scrape" in the Main tab
4. **Monitor progress** through the real-time log
5. **View results** by clicking "Open Results" when complete

### Settings Configuration

#### Scraping Configuration
- **Target URL**: Trade show calendar website
- **Wait Seconds**: Delay between page loads (7-30 seconds)
- **Contact Delay**: Delay for website scraping (1-10 seconds)
- **Max Events**: Maximum events to collect (1-1000)
- **Headless Mode**: Run browser in background

#### Month Selection
- **Individual Year Control**: Set specific years for each month
- **Smart Defaults**: 
  - August-December: 2025
  - January-July: 2026
- **Selective Scraping**: Choose which months to process

### Output Format

The application generates `events.xlsx` with the following columns:

| Column | Description |
|--------|-------------|
| Event Name | Name of the trade show event |
| Dates | Event dates and duration |
| City | Event location city |
| Country | Event location country |
| Attendance | Expected attendance numbers |
| Exhibitors | Number of exhibitors |
| Website | Event website URL |
| Email | Contact email address |
| Company Name | Extracted company name |
| Company Name Source | Source of company name (GPT/Website) |

## ğŸ”§ Development

### Project Structure
```
prospect-data-discovery-project/
â”œâ”€â”€ event_scraper_gui.py      # Main GUI application
â”œâ”€â”€ event_scraper.py          # Core scraping logic
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ README.md                # This file
â”œâ”€â”€ env_example.txt          # Environment variables template
â”œâ”€â”€ .gitignore              # Git ignore rules
â”œâ”€â”€ EventScraper.exe        # Pre-built executable
â””â”€â”€ venv/                   # Virtual environment (not in repo)
```

### Building the Executable
```bash
# Activate virtual environment
.\venv\Scripts\activate

# Install PyInstaller
pip install pyinstaller

# Build executable
pyinstaller --onefile --windowed --name EventScraper event_scraper_gui.py
```

## âš ï¸ Important Notes

### API Usage
- **OpenAI API**: Required for company name extraction
- **Rate Limits**: Respect API usage limits
- **Costs**: API calls may incur charges
- **Fallback**: Works without API key (limited functionality)

### Scraping Ethics
- **Respectful Scraping**: Built-in delays to avoid overwhelming servers
- **Terms of Service**: Ensure compliance with target websites
- **Rate Limiting**: Configurable delays between requests
- **Error Handling**: Graceful handling of network issues

### Performance Considerations
- **Memory Usage**: Large datasets may require significant RAM
- **Processing Time**: Scraping can take 30+ minutes for large datasets
- **Network Speed**: Faster internet improves scraping speed
- **Browser Resources**: Chrome WebDriver requires system resources

### Debug Mode
For development, run with console output:
```bash
python event_scraper_gui.py
```

## ğŸ“ Support

For issues and questions:
- **GitHub Issues**: Report bugs and feature requests
- **Documentation**: Check this README for usage instructions
- **Configuration**: Review settings in the GUI

## ğŸ‰ Acknowledgments

- **Selenium**: Browser automation framework
- **OpenAI**: GPT-4 API for intelligent text processing
- **Tkinter**: GUI framework
- **PyInstaller**: Executable packaging
- **BeautifulSoup**: HTML parsing library